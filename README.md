Meloson is an experimental generative transformer model that uses GPT-2 architecture to predict the next token to engender music no one would've ever heard before.
It was trained on the base GPT-2 architecture from ground-up from thousands of hours of piano midi music using v3-8 TPU.

The model can be downloaded through this link:
https://drive.google.com/file/d/10PWEQEPD-qOgam5XMALUrV3wmO9D8gxd/view?usp=sharing

Please use the train script to train your model ground-up or to fine-tune on your own dataset.

Use the inference script to create your own generations with your own primers.

Thank you so much for the TRC team for providing training resources!
